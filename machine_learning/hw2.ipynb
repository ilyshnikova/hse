{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 2\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 11.10.2016\n",
    "\n",
    "Срок сдачи: 24.10.2016 23:59MSK\n",
    "\n",
    "### О задании\n",
    "На сайтах для поиска работы можно найти сотни тысяч объявлений, каждое из которых состоит из пространного описания вакансии и предлагаемой зарплаты. Есть ли связь между описанием и зарплатой? Существуют ли определенные слова, которые наиболее сильно характеризуют зарплату? Можно ли найти другие информативные факторы? Вам предстоит ответить на эти вопросы, проанализировав выборку объявлений о работе в Великобритании.\n",
    "\n",
    "Практическое задание 2 посвящено работе с текстовыми данными и категориальными признаками и задачам бинарной классификации. Вы научитесь:\n",
    " * работать с категориальными признаками;\n",
    " * строить вещественные представления текстовых данных;\n",
    " * обучать и строить прогнозы линейных классификаторов при помощи scikit-learn и Vowpal Wabbit;\n",
    " * тестировать модели и проводить оценку качества в задачах бинарной классификации.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Кроме того, некоторые из заданий являются опциональными (необязательными), однако за их выполнение можно получить дополнительные баллы, которые позднее будут учитываться при проставлении оценок автоматом по курсу.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW2_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW2_IvanovII.ipynb*). Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+141@gmail.com для студентов группы БПМИ-141)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Как было упомянуто ранее, в рамках данного задания мы будем решать задачу бинарной классификации для предсказания уровня заработной платы по тексту объявления о вакансии на примере набора данных с соревнования [Adzuna - Job Salary Prediction](https://www.kaggle.com/c/job-salary-prediction). Для начала пройдите по [ссылке](https://www.kaggle.com/c/job-salary-prediction/data) и скачайте файл Train_rev1 (при необходимости, зарегистрируйтесь на Kaggle).\n",
    "\n",
    "Посмотрим на данные в файле и загрузим их в DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,Title,FullDescription,LocationRaw,LocationNormalized,ContractType,ContractTime,Company,Category,SalaryRaw,SalaryNormalized,SourceName\r",
      "\r\n",
      "12612628,Engineering Systems Analyst,\"Engineering Systems Analyst Dorking Surrey Salary ****K Our client is located in Dorking, Surrey and are looking for Engineering Systems Analyst our client provides specialist software development Keywords Mathematical Modelling, Risk Analysis, System Modelling, Optimisation, MISER, PIONEEER Engineering Systems Analyst Dorking Surrey Salary ****K\",\"Dorking, Surrey, Surrey\",Dorking,,permanent,Gregory Martin International,Engineering Jobs,20000 - 30000/annum 20-30K,25000,cv-library.co.uk\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# print first 2 rows from Train_rev1.csv\n",
    "!head -n 2 Train_rev1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244768, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Train_rev1.csv', sep=',')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В оригинальной постановке предлагается рассматривать признак SalaryNormalized как целевой и решать задачу регрессии, однако в рамках данного задания мы сведём её к задаче бинарной классификации, разделив объекты на 2 группы: объявления о вакансиях с низкой и высокой зарплатами соответственно.\n",
    "\n",
    "<img src = \"http://salt.uaa.alaska.edu/kath/kti/mean_median2.gif\">\n",
    "\n",
    "В качестве порога разбиения объектов на группы будем рассматривать медиану признака SalaryNormalized. Заметим, что таким образом мы автоматически получим задачу классификации со сбалансированными классами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABVsAAAK9CAYAAAA647xtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACADvz/F6M1pxeBLGIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e4cd14ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# salary histogramm\n",
    "median = np.median(df['SalaryNormalized'])\n",
    "\n",
    "figsize(16,8)\n",
    "plt.hist(df['SalaryNormalized'], bins=50)\n",
    "plt.axvline(median, c='r')\n",
    "plt.xlabel('salary', fontsize=20)\n",
    "plt.ylabel('count', fontsize=20)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим последние шаги по подготовке датасета:\n",
    "- бинаризуем признак SalaryNomalized по описанному ранее порогу;\n",
    "- исключим из выборки признак SalaryRaw, чтобы устранить утечку целевой переменной в признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "   SalaryNormalized        SourceName  \n",
       "0                 0  cv-library.co.uk  \n",
       "1                 0  cv-library.co.uk  \n",
       "2                 0  cv-library.co.uk  \n",
       "3                 0  cv-library.co.uk  \n",
       "4                 0  cv-library.co.uk  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SalaryNormalized'] = (df['SalaryNormalized'] > median).astype(int)\n",
    "df.drop('SalaryRaw', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (0 баллов) Разбейте получившуюся выборку на обучающую и контрольную в соотношении 70/30 с использованием перемешивания объектов.\n",
    "\n",
    "При разбиении используйте значение параметра random_state=42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_testing_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "if is_testing_mode:\n",
    "    df = df.head(10000)\n",
    "\n",
    "Y = df['SalaryNormalized']\n",
    "X = df.drop('SalaryNormalized', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация\n",
    "\n",
    "Как правило, модели, используемые в машинном обучении, применяются в предположении, что матрица \"объект-признак\" является вещественнозначной. Поэтому при работе с категориальными признаками и текстами сперва их необходимо привести к вещественному виду.\n",
    "\n",
    "Заметим, что в нашей задаче есть признаки, являющиеся текстами произвольной природы (Title, FullDescription), и категориальные признаки, принимающие ограниченное число значений (ContractType, Category и др.).\n",
    "\n",
    "Самый простой и понятный способ преобразования текстовых данных — векторизация. В этом случае для каждого слова, встречающегося в некотором набре текстов мы создаём отдельный новый признак, который будет равен $1$, когда слово встречается в заданном объекте, и $0$ – в противном случае.\n",
    "\n",
    "#### 2. (0.5 балла) Создайте текстовое описание объектов обучающей и контрольной выборок, объединив значения всех признаков каждого объекта выборки через символы пробела. После этого получите признаковое описание объектов, осуществив векторизацию получившихся текстов при помощи [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), обучив его на обучающей выборке и применив на контрольной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/pandas/core/frame.py:2824: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def get_text_col(x):\n",
    "    cat_features_mask = (x.dtypes == \"object\").values\n",
    "    data_str = x[x.columns[cat_features_mask]]\n",
    "    data_str.fillna('nan', inplace=True)\n",
    "    text = data_str[data_str.columns[0]]\n",
    "    data_str.columns\n",
    "    for col in data_str.columns[1:]:\n",
    "        text += ' ' + data_str[col]\n",
    "    return text\n",
    "    \n",
    "text_train = get_text_col(X_train)\n",
    "text_test = get_text_col(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(encoding='utf8', min_df=5)\n",
    "fit_vect = vectorizer.fit(text_train)\n",
    "\n",
    "train = vectorizer.transform(text_train)\n",
    "test = vectorizer.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (1.5 балла) Обучите следующие модели на обучающей выборке:\n",
    " - [логистическую регрессию](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из модуля sklearn с параметрами по умолчанию;\n",
    " - логистическую регрессию при помощи Vowpal Wabbit с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file\n",
    "dump_svmlight_file(train, y_train, \"train.txt\")\n",
    "dump_svmlight_file(test, y_test, \"test.txt\")\n",
    "! sed -i 's/^0 /-1 |features /g' train.txt\n",
    "! sed -i 's/^1 /1 |features /g' train.txt\n",
    "! sed -i 's/^0 /-1 |features /g' test.txt\n",
    "! sed -i 's/^1 /1 |features /g' test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000      229\n",
      "0.611652 0.530157            2            2.0  -1.0000   0.4115       90\n",
      "0.488651 0.365649            4            4.0  -1.0000   0.2128      168\n",
      "0.908853 1.329055            8            8.0  -1.0000   0.4008      126\n",
      "0.802315 0.695778           16           16.0  -1.0000   0.5688      164\n",
      "0.764599 0.726882           32           32.0  -1.0000   0.6581      194\n",
      "0.711296 0.657992           64           64.0  -1.0000   0.1751      241\n",
      "0.685313 0.659331          128          128.0  -1.0000   0.3844      229\n",
      "0.643729 0.602144          256          256.0  -1.0000   0.2879      122\n",
      "0.600244 0.556759          512          512.0   1.0000   0.7500       96\n",
      "0.563543 0.526842         1024         1024.0   1.0000   0.2971      102\n",
      "0.527185 0.490828         2048         2048.0   1.0000   0.7836      160\n",
      "0.509153 0.491121         4096         4096.0   1.0000   0.7427      122\n",
      "0.475166 0.441178         8192         8192.0   1.0000   0.5061       72\n",
      "0.445603 0.416040        16384        16384.0   1.0000   0.8531      178\n",
      "0.418514 0.391426        32768        32768.0   1.0000   0.8142      123\n",
      "0.392107 0.365700        65536        65536.0  -1.0000   0.0978      279\n",
      "0.369078 0.346049       131072       131072.0  -1.0000   0.1118      123\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 171337\n",
      "passes used = 1\n",
      "weighted example sum = 171337.000000\n",
      "weighted label sum = -5161.000000\n",
      "average loss = 0.360035\n",
      "best constant = -0.060262\n",
      "best constant's loss = 0.692693\n",
      "total feature number = 25626213\n"
     ]
    }
   ],
   "source": [
    "! vw --link logistic --loss_function logistic --data train.txt -f model.vw --invert_hash /root/readable_model.vw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873795230883 0.869502686087 \n",
      " [[33343  4597]\n",
      " [ 4658 30833]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "y_pred = logreg.predict(test)\n",
    "first_linreg_score = roc_auc_score(y_test, y_pred)\n",
    "first_f1_score = f1_score(y_test, y_pred)\n",
    "first_cm_score = confusion_matrix(y_test, y_pred)\n",
    "print(first_linreg_score, first_f1_score, \"\\n\", first_cm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (0.5 балла) Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для каждой из построенных в п. 3 моделей на контрольной выборке. Сравните построенные модели по качеству их работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = raw_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.843930 0.843930            1            1.0  -1.0000   0.5700      207\n",
      "0.426326 0.008722            2            2.0  -1.0000   0.0087      235\n",
      "0.516298 0.606269            4            4.0  -1.0000   0.4590       45\n",
      "0.337346 0.158395            8            8.0  -1.0000   0.0329      135\n",
      "0.360707 0.384068           16           16.0   1.0000   0.7549      235\n",
      "0.270329 0.179952           32           32.0   1.0000   0.7502      154\n",
      "0.231712 0.193095           64           64.0   1.0000   0.9379      125\n",
      "0.261072 0.290432          128          128.0   1.0000   0.9207      154\n",
      "0.293860 0.326649          256          256.0   1.0000   0.4292      231\n",
      "0.300316 0.306771          512          512.0  -1.0000   0.0203      167\n",
      "0.300859 0.301403         1024         1024.0   1.0000   0.4565      155\n",
      "0.309695 0.318531         2048         2048.0  -1.0000   0.0504      122\n",
      "0.327866 0.346038         4096         4096.0   1.0000   0.6621      156\n",
      "0.327728 0.327589         8192         8192.0   1.0000   0.6376      176\n",
      "0.326456 0.325184        16384        16384.0  -1.0000   0.8363      138\n",
      "0.329564 0.332673        32768        32768.0  -1.0000   0.9472      166\n",
      "0.330926 0.332287        65536        65536.0   1.0000   0.4630      124\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 73431\n",
      "passes used = 1\n",
      "weighted example sum = 73431.000000\n",
      "weighted label sum = -2449.000000\n",
      "average loss = 0.330395\n",
      "best constant = -0.066727\n",
      "best constant's loss = 0.692591\n",
      "total feature number = 11016931\n"
     ]
    }
   ],
   "source": [
    "!`vw --data test.txt -t -i model.vw --loss_function logistic -r raw_predictions.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846265866745 0.830915960753 \n",
      " [[35064  2876]\n",
      " [ 8222 27269]]\n"
     ]
    }
   ],
   "source": [
    "wv_y_pred = []\n",
    "with open('raw_predictions.txt') as f:\n",
    "     wv_y_pred = f.readlines()\n",
    "\n",
    "        \n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "wv_y_pred = [1 if float(i) > 0.5 else 0 for i in wv_y_pred]\n",
    "vw_first_linreg_score = roc_auc_score(y_test, wv_y_pred)\n",
    "\n",
    "vw_first_f1_score = f1_score(y_test, wv_y_pred)\n",
    "vw_first_cm_score = confusion_matrix(y_test, wv_y_pred)\n",
    "print(vw_first_linreg_score, vw_first_f1_score, \"\\n\", vw_first_cm_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. (1 балл) Отсортируйте веса признаков для модели логистической регрессии из scikit-learn, полученной в п. 2. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретируйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min\n",
      "europeanmanagementaccountant_job -1.97818018542e-06\n",
      "pm130123 -1.97818018542e-06\n",
      "alternating -2.25869959099e-06\n",
      "detailedlevel 7.02977836882e-06\n",
      "precompletion -7.92821503801e-06\n",
      "kellieann 8.04741947059e-06\n",
      "hukins 8.04741947059e-06\n",
      "visitsdeveloping -1.06720404155e-05\n",
      "negotiationfor 1.38941874706e-05\n",
      "v2012 1.92936375553e-05\n",
      "max\n",
      "targetjobs 1.52826319491\n",
      "optometrist 1.59119655352\n",
      "huntswood 1.6468965302\n",
      "qsw 1.65384093404\n",
      "hcpc 1.91340174673\n",
      "nijobfinder -2.12499628772\n",
      "a24 2.12845377117\n",
      "studentship -2.4347189745\n",
      "elance -3.1993425059\n",
      "theladders 3.67554320022\n"
     ]
    }
   ],
   "source": [
    "top_size = 10\n",
    "indexes = np.argsort([abs(i) for i in logreg.coef_])[0]\n",
    "columns=vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "print('min')\n",
    "for i in range(0,top_size):\n",
    "    print(columns[indexes[i]], logreg.coef_[0][indexes[i]])\n",
    "     \n",
    "print('max')\n",
    "for i in range(len(indexes) - top_size,len(indexes)):\n",
    "    print(columns[indexes[i]], logreg.coef_[0][indexes[i]])\n",
    "        \n",
    "#слова действительно похожи на те от которых зависит уровень зарплаты \n",
    "# например studentship -- на стажировках платят не много \n",
    "# a24 -- какая то компания у которой возможно зарплата как то вделяется на фоне других"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. (0.5 доп. балла) Отсортируйте веса признаков для модели логистической регрессии, полученной в п. 2 при помощи Vowpal Wabbit. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретирйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min\n",
      "nijobfinder -1.105152\n",
      "jobsitnmark -1.104159\n",
      "findababysitter -1.069271\n",
      "assistantaccountant_job -1.031723\n",
      "administrator_job -1.015452\n",
      "hradministrator_job -0.945075\n",
      "revitalised -0.943932\n",
      "assistantmanager_job -0.9249\n",
      "accountsassistant_job -0.919423\n",
      "kitchenmanager_job -0.890271\n",
      "max\n",
      "legalweekjobs 0.806651\n",
      "careersinaudit 0.808615\n",
      "commercialaccountant_job 0.825566\n",
      "totallyexec 0.874948\n",
      "actuaryjobs 0.984178\n",
      "ryanh 0.99589\n",
      "infochasemedical 1.014803\n",
      "efinancialcareers 1.177208\n",
      "oilandgasjobsearch 1.300049\n",
      "theladders 2.601045\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_feature_weights():\n",
    "    with open(\"readable_model.vw\") as f:\n",
    "        for line in f.readlines():\n",
    "            mgroup = re.match(\"^features\\^(\\d+):(\\d+):(.*)$\", line)\n",
    "            if mgroup:\n",
    "                feature_name = mgroup.group(1)\n",
    "                feature_weight = mgroup.group(3)\n",
    "                yield (float(feature_weight), int(feature_name))\n",
    "\n",
    "result_list = list(parse_feature_weights())\n",
    "result_list.sort()\n",
    "columns=vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "print('min')\n",
    "for i in range(0, top_size):\n",
    "    print(columns[result_list[i][1]], result_list[i][0]) \n",
    "    \n",
    "print('max')\n",
    "for i in range(len(result_list) - top_size, len(result_list)):\n",
    "    print(columns[result_list[i][1]], result_list[i][0]) \n",
    "    \n",
    "\n",
    "#слова не очень похожи на те от которых зависит уровень зарплаты \n",
    "#theladders -- Ladders, Inc. is a United States-based company providing an online job search service "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Ещё один способ работы с текстовыми данными — [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf) (**T**erm **F**requency–**I**nverse **D**ocument **F**requency). Рассмотрим коллекцию текстов $D$.  Для каждого уникального слова $t$ из документа $d \\in D$ вычислим следующие величины:\n",
    "\n",
    "1. Term Frequency – количество вхождений слова в отношении к общему числу слов в тексте:\n",
    "$$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$$\n",
    "где $n_{td}$ — количество вхождений слова $t$ в текст $d$.\n",
    "1. Inverse Document Frequency\n",
    "$$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$$\n",
    "где $\\left| \\{d\\in D: t \\in d\\} \\right|$ – количество текстов в коллекции, содержащих слово $t$.\n",
    "\n",
    "Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину:\n",
    "$$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$$\n",
    "\n",
    "Отметим, что значение $\\text{tf}(t, d)$ корректируется для часто встречающихся общеупотребимых слов при помощи значения $\\text{idf}(t, D).$\n",
    "\n",
    "Признаковым описанием одного объекта $d \\in D$ будет вектор $\\bigg(\\text{tf-idf}(t,d, D)\\bigg)_{t\\in V}$, где $V$ – словарь всех слов, встречающихся в коллекции $D$.\n",
    "\n",
    "#### 7. (0.5 балла) Создайте текстовое описание объектов обучающей и контрольной выборок, объединив значения всех признаков каждого объекта выборки через символы пробела. После этого получите признаковое описание объектов, вычислив вектор tf-idf для каждого объекта помощи [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), обучив его на обучающей выборке и применив на контрольной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train\n",
    "text_test\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(encoding='utf8', min_df=5)\n",
    "_ = vectorizer.fit(text_train)\n",
    "\n",
    "train = vectorizer.transform(text_train)\n",
    "test = vectorizer.transform(text_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. (0 баллов) Обучите следующие модели на обучающей выборке:\n",
    "- [логистическую регрессию](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из модуля sklearn с параметрами по умолчанию;\n",
    "- логистическую регрессию при помощи Vowpal Wabbit с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000      229\n",
      "0.557564 0.421980            2            2.0  -1.0000   0.3443       90\n",
      "0.444525 0.331487            4            4.0  -1.0000   0.2111      168\n",
      "0.691462 0.938398            8            8.0  -1.0000   0.4028      126\n",
      "0.702771 0.714081           16           16.0  -1.0000   0.5447      164\n",
      "0.708598 0.714425           32           32.0  -1.0000   0.6402      194\n",
      "0.681388 0.654177           64           64.0  -1.0000   0.2026      241\n",
      "0.664034 0.646680          128          128.0  -1.0000   0.4226      229\n",
      "0.630808 0.597582          256          256.0  -1.0000   0.3227      122\n",
      "0.586339 0.541869          512          512.0   1.0000   0.8740       96\n",
      "0.550504 0.514669         1024         1024.0   1.0000   0.3012      102\n",
      "0.510633 0.470763         2048         2048.0   1.0000   0.7357      160\n",
      "0.489283 0.467932         4096         4096.0   1.0000   0.8334      122\n",
      "0.455375 0.421468         8192         8192.0   1.0000   0.5516       72\n",
      "0.423286 0.391196        16384        16384.0   1.0000   0.8666      178\n",
      "0.394433 0.365580        32768        32768.0   1.0000   0.8934      123\n",
      "0.368241 0.342049        65536        65536.0  -1.0000   0.2720      279\n",
      "0.346003 0.323766       131072       131072.0  -1.0000   0.0865      123\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 171337\n",
      "passes used = 1\n",
      "weighted example sum = 171337.000000\n",
      "weighted label sum = -5161.000000\n",
      "average loss = 0.337771\n",
      "best constant = -0.060262\n",
      "best constant's loss = 0.692693\n",
      "total feature number = 25626213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import dump_svmlight_file\n",
    "dump_svmlight_file(train, y_train, \"train.txt\")\n",
    "dump_svmlight_file(test, y_test, \"test.txt\")\n",
    "! sed -i 's/^0 /-1 |features /g' train.txt\n",
    "! sed -i 's/^1 /1 |features /g' train.txt\n",
    "! sed -i 's/^0 /-1 |features /g' test.txt\n",
    "! sed -i 's/^1 /1 |features /g' test.txt\n",
    "! vw --link logistic --loss_function logistic --data train.txt -f model.vw --invert_hash /root/readable_model.vw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. (0.5 балла) Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для каждой из построенных в п. 8 моделей на контрольной выборке. Сравните построенные модели по качеству их работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score : first: 0.873795230883 || second: 0.86874186937\n",
      "f1_score : first: 0.869502686087 || second: 0.864764738076\n",
      "confusion_matrix : first:\n",
      " [[33343  4597]\n",
      " [ 4658 30833]] \n",
      "|| second:\n",
      " [[32982  4958]\n",
      " [ 4679 30812]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "y_pred = logreg.predict(test)\n",
    "\n",
    "print('roc_auc_score : first:', first_linreg_score, '||', 'second:', roc_auc_score(y_test, y_pred))\n",
    "print('f1_score : first:', first_f1_score, '||', 'second:', f1_score(y_test, y_pred))\n",
    "print('confusion_matrix : first:\\n', first_cm_score, '\\n||', 'second:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = raw_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.837535 0.837535            1            1.0  -1.0000   0.5672      207\n",
      "0.456690 0.075844            2            2.0  -1.0000   0.0730      235\n",
      "0.549657 0.642624            4            4.0  -1.0000   0.3498       45\n",
      "0.314794 0.079931            8            8.0  -1.0000   0.0385      135\n",
      "0.325506 0.336218           16           16.0   1.0000   0.6582      235\n",
      "0.229904 0.134303           32           32.0   1.0000   0.7245      154\n",
      "0.201755 0.173607           64           64.0   1.0000   0.9857      125\n",
      "0.236962 0.272168          128          128.0   1.0000   0.9349      154\n",
      "0.288495 0.340028          256          256.0   1.0000   0.6160      231\n",
      "0.284554 0.280613          512          512.0  -1.0000   0.0155      167\n",
      "0.284018 0.283483         1024         1024.0   1.0000   0.5865      155\n",
      "0.292440 0.300862         2048         2048.0  -1.0000   0.0376      122\n",
      "0.304793 0.317147         4096         4096.0   1.0000   0.6745      156\n",
      "0.305302 0.305810         8192         8192.0   1.0000   0.7004      176\n",
      "0.304404 0.303507        16384        16384.0  -1.0000   0.9101      138\n",
      "0.307130 0.309856        32768        32768.0  -1.0000   0.9506      166\n",
      "0.309429 0.311728        65536        65536.0   1.0000   0.5228      124\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 73431\n",
      "passes used = 1\n",
      "weighted example sum = 73431.000000\n",
      "weighted label sum = -2449.000000\n",
      "average loss = 0.308932\n",
      "best constant = -0.066727\n",
      "best constant's loss = 0.692591\n",
      "total feature number = 11016931\n"
     ]
    }
   ],
   "source": [
    "!`vw --data test.txt -t -i model.vw --loss_function logistic -r raw_predictions.txt `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score : first: 0.846265866745 || second: 0.858757532536\n",
      "f1_score : first: 0.830915960753 || second: 0.847128138412\n",
      "confusion_matrix : first:\n",
      " [[35064  2876]\n",
      " [ 8222 27269]] \n",
      "|| second:\n",
      " [[34883  3057]\n",
      " [ 7166 28325]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "y_pred = []\n",
    "with open('raw_predictions.txt') as f:\n",
    "     y_pred = f.readlines()\n",
    "\n",
    "y_pred = [1 if float(i) > 0.5 else 0 for i in y_pred]\n",
    "\n",
    "print('roc_auc_score : first:', vw_first_linreg_score, '||', 'second:', roc_auc_score(y_test, y_pred))\n",
    "print('f1_score : first:', vw_first_f1_score, '||', 'second:', f1_score(y_test, y_pred))\n",
    "print('confusion_matrix : first:\\n', vw_first_cm_score, '\\n||', 'second:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. (0.5 балла) Сравните значения метрик из п. 9 со значениями, полученными в п. 5, и сравните соответствующие модели по качеству из работы.\n",
    "\n",
    "**Ответ**: В случае логистической регрессии из sklearn  значение auc-roc и f1_score уменьшилось, так же по матрице ошибок видно что мы стали делать меньше обштбок второго рода и больше первого рода.\n",
    "\n",
    " В случае логистической регрессии из vw  значение auc-roc и f1_score наоборот увеличилось, так же по матрице ошибок видно что мы стали делать меньше обштбок первого рода но больше второго рода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. (1 балл) Отсортируйте веса признаков для каждой из полученных в п. 8 моделей. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретирйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min\n",
      "todayhays 2.41610720242e-06\n",
      "whitepertemps 5.85486935195e-06\n",
      "recyling -1.25834673976e-05\n",
      "copes 2.28314253222e-05\n",
      "livingstone 2.79225185686e-05\n",
      "sportsmark -3.33801069691e-05\n",
      "refurbishing -3.94882212767e-05\n",
      "cwsmeriaid 4.28973672333e-05\n",
      "iniative 4.78632365809e-05\n",
      "requited 4.92168915345e-05\n",
      "max\n",
      "london 6.2765960921\n",
      "head 7.07286693571\n",
      "jobcentre -7.33165899363\n",
      "senior 7.39313841688\n",
      "junior -7.77731735176\n",
      "manager 7.78582669035\n",
      "director 7.79908643596\n",
      "optometrist 8.8772196722\n",
      "graduate -10.0480773619\n",
      "assistant -10.8988826337\n"
     ]
    }
   ],
   "source": [
    "indexes = np.argsort([abs(i) for i in logreg.coef_])[0]\n",
    "columns=vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "print('min')\n",
    "for i in range(0,top_size):\n",
    "    print(columns[indexes[i]], logreg.coef_[0][indexes[i]])\n",
    "     \n",
    "print('max')\n",
    "for i in range(len(indexes) - top_size,len(indexes)):\n",
    "    print(columns[indexes[i]], logreg.coef_[0][indexes[i]])\n",
    "        \n",
    "#слова действительно похожи на те от которых зависит уровень зарплаты  -- гораздо лучше чем предыдущие способы \n",
    "# все слова очевидно напрямую связанные с зрплатой -- senior -- junior --  manager -- director -- graduate(лол -10.0480773619) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. (0.5 доп. балла) Отсортируйте веса признаков для модели логистической регрессии, полученной в п. 8 при помощи Vowpal Wabbit. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретирйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min\n",
      "stokenchurch 0.000135\n",
      "ecom 0.000151\n",
      "nes 0.000158\n",
      "lifelimiting 0.000213\n",
      "blumenthal 0.000279\n",
      "engraving 0.000279\n",
      "graphics 0.000283\n",
      "coffees 0.000322\n",
      "collaborations 0.000369\n",
      "kk 0.000389\n",
      "max\n",
      "revitalised 8.309172\n",
      "crowncarveries 8.309795\n",
      "milkmen 8.377786\n",
      "vehiclepurchasercarsales_job 8.381116\n",
      "airmonitoring 8.440272\n",
      "spoton 8.77332\n",
      "hearingcareflamehealth 8.975466\n",
      "navisionjobs 9.648344\n",
      "yearscoring 13.331036\n",
      "theladders 16.332384\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_feature_weights():\n",
    "    with open(\"readable_model.vw\") as f:\n",
    "        for line in f.readlines():\n",
    "            mgroup = re.match(\"^features\\^(\\d+):(\\d+):(.*)$\", line)\n",
    "            if mgroup:\n",
    "                feature_name = mgroup.group(1)\n",
    "                feature_weight = mgroup.group(3)\n",
    "                yield (abs(float(feature_weight)), int(feature_name))\n",
    "\n",
    "result_list = list(parse_feature_weights())\n",
    "result_list.sort()\n",
    "columns=vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "print('min')\n",
    "for i in range(0, top_size):\n",
    "    print(columns[result_list[i][1]], result_list[i][0]) \n",
    "    \n",
    "print('max')\n",
    "for i in range(len(result_list) - top_size, len(result_list)):\n",
    "    print(columns[result_list[i][1]], result_list[i][0]) \n",
    "    \n",
    "\n",
    "#слова действительно похожи на те от которых зависит уровень зарплаты \n",
    "#  theladders -- сайт с вакансиями -- видимо это какой то сайт на котором размещают васокооплачиваемую работу "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Счётчики\n",
    "\n",
    "Ранее в рамках данного задания при построении моделей мы объединяли значения всех признаков в единую строку, что предполагает равноправность всех признаков. Однако заметим, что в этом случае мы допускаем потерю информации: слово \"Glasgow\" может по-разному влиять на зарплату, если оно находится в названии объявления и в геолокации. Чтобы устранить этот недостаток, при создании текстового описания объекта будем объединять только значения признаков Title и FullDescription, а остальные будем рассматривать как категориальные. При этом с полученным текстовым описанием объекта будем работать, как раньше (при помощи векторизации или tf-idf), а для кодирования категориальных признаков используем **счётчики**.\n",
    "\n",
    "Идея этого метода состоит в том, чтобы заменить значение категориального признака на вероятность того, что объект с данным значением признака относится к положительному классу. Опишем эту идею более формально. Пусть у нас есть выборка $X = \\{ (x_i, y_i) \\}_{i=1}^l,$ и $j$-ый признак принимает значения из множества $U_j = \\{ u_{jn}\\}_{n=1}^{N_j},$ где $N_j$ — количество различных значений $j$-ого признака. Пусть $x_{ij} = u_{jn},$ тогда заменим значения $j$-ого категориального признака объекта $x_i$ на следующую оценку: \n",
    "$$\\hat{P}(y_i=+1|x_{ij}=u_{jn}) = \\frac{\\sum_{m=1}^l \\left[ x_{mj} = u_{jn} \\right] \\left[ y_m = +1 \\right]}{\\sum_{m=1}^l \\left[ x_{mj} = u_{jn} \\right]}.$$\n",
    "\n",
    "Однако заметим, что при таком способе формирования счётчиков мы учитываем в формуле для объекта $x_i$ его метку $y_i$, тем самым вносим информацию об ответе в признаки. Чтобы устранить этот недостаток, при вычислении счётчика будем исключать из рассмотрения текущий объект, т.е. рассматривать следующую оценку:\n",
    "$$\\hat{P}(y_i=+1|X_{ij}=u_{jn}) = \\frac{\\sum_{m=1, \\\\ m \\ne i}^l \\left[ x_{mj} = u_{jn} \\right] \\left[ y_m = +1 \\right]}{\\sum_{m=1, \\\\ m \\ne i}^l \\left[ x_{mj} = u_{jn} \\right]},$$\n",
    "\n",
    "#### 13. (0.5 балла) Создайте текстовое описание объектов обучающей и контрольной выборок, объединив значения признаков Title и FullDescription каждого объекта выборки через символ пробела, после чего перейдите к признаковому описанию объектов, вычислив вектор tf-idf аналогично п. 7. (будет сделано в одной куче с 14 номером)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. (1 балл) Закодируйте категориальные признаки (все, кроме Title и FullDescription) при помощи [one-hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), после чего обучите логистическую регрессию (при помощи scikit-learn или Vowpal Wabbit) на обучающей выборке. Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для полученной модели на контрольной выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244768, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#cчкачиваю выборку\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Train_rev1.csv', sep=',')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "median = np.median(df['SalaryNormalized'])\n",
    "\n",
    "df['SalaryNormalized'] = (df['SalaryNormalized'] > median).astype(int)\n",
    "df.drop('SalaryRaw', axis=1, inplace=True)\n",
    "df.drop('LocationRaw', axis=1, inplace=True)\n",
    "df.drop('Id', axis=1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "Y = df['SalaryNormalized']\n",
    "X = df.drop('SalaryNormalized', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171337, 8)\n",
      "(171337,)\n"
     ]
    }
   ],
   "source": [
    "#беру от каждой компании только одно объявление а то все не влезает в память поэтому приходится оптимизировать\n",
    "companies = {}\n",
    "max_count = 1\n",
    "to_delete = []\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    comp = X_train.iloc[i]['Company']\n",
    "    companies.setdefault(comp, 0)\n",
    "    companies[comp] += 1\n",
    "    if companies[comp] > max_count:\n",
    "        to_delete += [i] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17751, 8)\n",
      "(17751,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#удаляю ненужные данные из сета\n",
    "len(to_delete)\n",
    "X_train.drop(X_train.index[to_delete], inplace=True)\n",
    "y_train.drop(y_train.index[to_delete], inplace=True)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Делю сет на две кучи\n",
    "text_train = X_train['Title'] + ' ' + X_train['FullDescription']\n",
    "text_test = X_test['Title'] + ' ' + X_test['FullDescription']\n",
    "text_train.fillna('nan', inplace=True)\n",
    "X_train.drop(['Title', 'FullDescription'], inplace=True, axis=1)\n",
    "X_test.drop(['Title', 'FullDescription'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True]\n",
      "Index(['LocationNormalized', 'ContractType', 'ContractTime', 'Company',\n",
      "       'Category', 'SourceName'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/pandas/core/frame.py:2824: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#делаю LabelEncoder признаков\n",
    "cat_features_mask = (X_train.dtypes == \"object\").values \n",
    "print(cat_features_mask)\n",
    "print(X_train.columns)\n",
    "df.fillna('nan', inplace=True)\n",
    "X_train.fillna('nan', inplace=True)\n",
    "X_test.fillna('nan', inplace=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_train.head()\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "for feature in X_train.columns[cat_features_mask]: \n",
    "    label_enc.fit(df[feature])\n",
    "    X_train[feature] = label_enc.transform(X_train[feature])\n",
    "    X_test[feature] = label_enc.transform(X_test[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#делаю OneHotEncoder для трейна\n",
    "enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "X_cat_np = enc.fit_transform(\n",
    "    X_train[\n",
    "        X_train.columns[cat_features_mask]\n",
    "    ]\n",
    ")\n",
    "X_cat_pd = pd.DataFrame(data=X_cat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# делаю TfidfVectorizer для трейна \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(encoding='utf8', min_df=5)\n",
    "train = vectorizer.fit_transform(text_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17751, 13350)\n",
      "(17751, 19270)\n"
     ]
    }
   ],
   "source": [
    "#записываю для vw в файл  трейн\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "print(pd.DataFrame(train.todense()).shape)\n",
    "print(X_cat_pd.shape)\n",
    "dump_svmlight_file(pd.concat([pd.DataFrame(train.todense()), X_cat_pd], axis=1), y_train, \"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000      226\n",
      "0.542842 0.392536            2            2.0  -1.0000   0.3247       87\n",
      "0.449483 0.356125            4            4.0  -1.0000   0.2285      168\n",
      "0.676287 0.903091            8            8.0  -1.0000   0.4008      118\n",
      "0.703580 0.730873           16           16.0  -1.0000   0.5433      160\n",
      "0.703952 0.704324           32           32.0  -1.0000   0.6265      188\n",
      "0.691287 0.678622           64           64.0   1.0000   0.5292      211\n",
      "0.662779 0.634270          128          128.0   1.0000   0.4887      131\n",
      "0.616999 0.571219          256          256.0  -1.0000   0.5508      344\n",
      "0.572844 0.528690          512          512.0  -1.0000   0.5506      199\n",
      "0.556611 0.540377         1024         1024.0   1.0000   0.6890      156\n",
      "0.521417 0.486224         2048         2048.0   1.0000   0.6643      164\n",
      "0.478777 0.436137         4096         4096.0  -1.0000   0.3546       61\n",
      "0.433353 0.387929         8192         8192.0   1.0000   0.9029      137\n",
      "0.384724 0.336095        16384        16384.0  -1.0000   0.0668      128\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 17751\n",
      "passes used = 1\n",
      "weighted example sum = 17751.000000\n",
      "weighted label sum = -4355.000000\n",
      "average loss = 0.379346\n",
      "best constant = -0.500893\n",
      "best constant's loss = 0.662742\n",
      "total feature number = 2455477\n"
     ]
    }
   ],
   "source": [
    "#обучаю vw на тестовых \n",
    "! ./run_vw\n",
    "# те же команды что и в предыдущих номерах толкьо в одном файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# нахожу в тесте признаки имеющие большие чем в трейне значения и удаляю потому что если это не сделать то не получится заикодить\n",
    "to_delete = []\n",
    "\n",
    "for r in range(0, X_test.shape[0]):\n",
    "    row = X_test.iloc[r]\n",
    "    if (row >= enc.n_values_).any(): \n",
    "        to_delete += [r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24746, 71926]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73431, 6)\n",
      "(73429, 6)\n",
      "(73431,)\n",
      "(73429,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73431,)\n",
      "(73429,)\n"
     ]
    }
   ],
   "source": [
    "# удаляю из тестовой выборки ненужные строчки\n",
    "print(X_test.shape)\n",
    "X_test.drop(X_test.index[to_delete], inplace=True)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(text_test.shape)\n",
    "text_test.drop(text_test.index[to_delete], inplace=True)\n",
    "print(text_test.shape)\n",
    "test = vectorizer.transform(text_test)\n",
    "print(y_test.shape)\n",
    "y_test.drop(y_test.index[to_delete], inplace=True)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#делаю OneHotEncoder для теста\n",
    "X_test_cat_np = enc.transform(\n",
    "    X_test[\n",
    "        X_test.columns[cat_features_mask]\n",
    "    ]\n",
    ")\n",
    "X_test_cat_pd = pd.DataFrame(data=X_test_cat_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del X_cat_pd\n",
    "del df\n",
    "del enc\n",
    "del label_enc \n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73429, 13350)\n",
      "(73429, 19270)\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(test.todense()).shape)\n",
    "print(X_test_cat_pd.shape)\n",
    "test = pd.concat([pd.DataFrame(test.todense()).head(17000), X_test_cat_pd.head(17000)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 32620)\n",
      "(73429,)\n"
     ]
    }
   ],
   "source": [
    "#записываю для vw в файл  трейн\n",
    "def print_for_vw(X, y, file_name):\n",
    "    f = open(file_name, 'w')\n",
    "    for i in range(X.shape[0]):\n",
    "        f.write(str(int(y.values[i])))\n",
    "        f.write(\" |features\")\n",
    "        for c in range(len(X.columns)):\n",
    "            f.write(\" \")\n",
    "            f.write(str(c))\n",
    "            f.write(\":\")\n",
    "            f.write(str(X.iloc[i][X.columns[c]]))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "print(test.shape)\n",
    "print(y_test.shape)\n",
    "dump_svmlight_file(test, y_test.head(17000), \"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = raw_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.846529 0.846529            1            1.0  -1.0000   0.5711      204\n",
      "0.665855 0.485182            2            2.0  -1.0000   0.3844      225\n",
      "0.704473 0.743090            4            4.0  -1.0000   0.5951       43\n",
      "0.441444 0.178415            8            8.0  -1.0000   0.1242      132\n",
      "0.417861 0.394279           16           16.0   1.0000   0.7790      230\n",
      "0.383540 0.349220           32           32.0   1.0000   0.6426      150\n",
      "0.320767 0.257993           64           64.0   1.0000   0.9657      123\n",
      "0.326298 0.331829          128          128.0   1.0000   0.8524      148\n",
      "0.356761 0.387224          256          256.0   1.0000   0.4788      209\n",
      "0.362364 0.367968          512          512.0  -1.0000   0.1551      163\n",
      "0.366510 0.370655         1024         1024.0   1.0000   0.4854      150\n",
      "0.380040 0.393571         2048         2048.0  -1.0000   0.1100      121\n",
      "0.392162 0.404283         4096         4096.0   1.0000   0.7472      149\n",
      "0.393072 0.393982         8192         8192.0   1.0000   0.6162      171\n",
      "0.393381 0.393691        16384        16384.0  -1.0000   0.8618      133\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 17000\n",
      "passes used = 1\n",
      "weighted example sum = 17000.000000\n",
      "weighted label sum = -572.000000\n",
      "average loss = 0.392956\n",
      "best constant = -0.067320\n",
      "best constant's loss = 0.692581\n",
      "total feature number = 2481198\n"
     ]
    }
   ],
   "source": [
    "! ./predict_vw \n",
    "# те же команды что и в предыдущих номерах толкьо в одном файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795344304259 0.764665286404 \n",
      " [[8050  736]\n",
      " [2674 5540]]\n"
     ]
    }
   ],
   "source": [
    "wv_y_pred = []\n",
    "with open('raw_predictions.txt') as f:\n",
    "     wv_y_pred = f.readlines()\n",
    "\n",
    "        \n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "wv_y_pred = [1 if float(i) > 0.5 else 0 for i in wv_y_pred]\n",
    "vw_first_linreg_score = roc_auc_score(y_test.head(17000), wv_y_pred)\n",
    "\n",
    "vw_first_f1_score = f1_score(y_test.head(17000), wv_y_pred)\n",
    "vw_first_cm_score = confusion_matrix(y_test.head(17000), wv_y_pred)\n",
    "print(vw_first_linreg_score, vw_first_f1_score, \"\\n\", vw_first_cm_score)\n",
    "\n",
    "#хначения хуже чем с предыдущих но скорее всего это вызвано тем что в данном случае из за one-hot признаки очень сиьно размножаются\n",
    "# поэтому мне было невозможно работать со всей выборкой поскольку оперативная память полностью исчерпывалась"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. (2 балла) Для выборки, полученной в п. 13, закодируйте категориальные признаки (все, кроме Title и FullDescription) при помощи счётчиков, после чего обучите логистическую регрессию (при помощи scikit-learn или Vowpal Wabbit) на обучающей выборке. Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для полученной модели на контрольной выборке. \n",
    "\n",
    "Уделите внимание оптимальности вычисления счётчиков!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. (0.5 балла) Сравните значения метрик из п. 15 со значениями, полученными в п. 14, и сделайте вывод о качестве классификации для каждого из методов кодирования категориальных признаков.\n",
    "\n",
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров\n",
    "\n",
    "#### 17. (1.5 доп. балла) Разбейте обучающую выборку на обучающую и валидационную в отношении 80/20. Для выборки, полученной в п. 13, подберите оптимальное количество фолдов, используемое при кодировании категориальных признаков (всех, кроме Title и FullDescription), путём оптимизации значения accuracy на валидационной выборке. Используйте следующие модели, аналогично также подобрав оптимальные значения указанных гиперпараметров:\n",
    "- логистическую регрессию из модуля sklearn с подбором коэффициента регуляризации;\n",
    "- логистическую регрессию при помощи Vowpal Wabbit с подбором следующих гиперпараметров:\n",
    "    - коэффициент регуляризации (--l2);\n",
    "    - количество эпох (--passes);\n",
    "    - длина градиентного шага (-l);\n",
    "    - длина N-грамм (--ngram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. (0.5 доп. балла) Обучите указанные выше модели на обучающей выборке для оптимальных значений гиперпараметров, найденных в п. 17, после чего для каждой из моделей вычислите значения ROC-AUC, F-меры, а также постройте матрицу ошибок на контрольной выборке. Как качество классификации при помощи полученных в данном разделе моделей соотносится с моделями, полученными в предыдущих разделах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями по поводу этого задания."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь — вставить вашу вторую любимую смешную картинку."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь — посоветовать преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
